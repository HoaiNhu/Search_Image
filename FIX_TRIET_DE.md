# üö® FIX TRI·ªÜT ƒê·ªÇ - Out of Memory Khi G·ªçi API

## ‚ùå V·∫•n ƒê·ªÅ M·ªõi

Deploy xong nh∆∞ng **KHI G·ªåI API** th√¨ v·∫´n b·ªã:
```
Ran out of memory (used over 512MB)
```

**Nguy√™n nh√¢n:** 
- Khi g·ªçi API ‚Üí Load model CLIP (~150MB)
- + Load products t·ª´ MongoDB (~100-200MB n·∫øu nhi·ªÅu)
- + Process request (~50-100MB)
- = **T·ªîNG: 300-450MB** nh∆∞ng v·∫´n c√≥ th·ªÉ v∆∞·ª£t 512MB khi c√≥ spike!

---

## ‚úÖ Gi·∫£i Ph√°p TRI·ªÜT ƒê·ªÇ

### 1. **Gi·ªõi H·∫°n S·ªë Products** (QUAN TR·ªåNG NH·∫§T!)
- Thay v√¨ load T·∫§T C·∫¢ products t·ª´ MongoDB
- Gi·ªù ch·ªâ load **50 products ƒë·∫ßu ti√™n**
- Gi·∫£m memory t·ª´ ~200MB xu·ªëng ~20MB!

### 2. **Force Garbage Collection**
- T·ª± ƒë·ªông d·ªçn d·∫πp memory sau m·ªói request
- Gi·∫£i ph√≥ng memory ngay l·∫≠p t·ª©c

### 3. **Batch Size Nh·ªè H∆°n**
- Process 4 items m·ªói l·∫ßn thay v√¨ 16
- Gi·∫£m memory spike

---

## üöÄ C√°ch Deploy (3 B∆Ø·ªöC)

### B∆Ø·ªöC 1: Update Environment Variables Tr√™n Render

V√†o **Render Dashboard** ‚Üí Service ‚Üí **Environment** tab

**TH√äM 2 BI·∫æN M·ªöI:**
```
MAX_PRODUCTS=50
ENABLE_GC=true
```

**ƒê·∫¢M B·∫¢O C√ÅC BI·∫æN SAU ƒê√É C√ì:**
```
CACHE_PRODUCTS=false
LAZY_LOAD_MODEL=true
MAX_BATCH_SIZE=4
```

### B∆Ø·ªöC 2: Update Start Command

V√†o tab **Settings** ‚Üí S·ª≠a **Start Command**:
```bash
cd src && uvicorn main:app --host 0.0.0.0 --port $PORT --workers 1 --limit-concurrency 5 --timeout-keep-alive 30
```

### B∆Ø·ªöC 3: Deploy

```bash
git add .
git commit -m "fix: drastic memory reduction - limit to 50 products"
git push origin main
```

Ho·∫∑c click **Manual Deploy** tr√™n Render

---

## üìä So S√°nh Memory

| Component | Tr∆∞·ªõc | Sau | Saved |
|-----------|-------|-----|-------|
| **Model CLIP** | 150MB | 150MB | - |
| **Products Data** | 200MB | 20MB | **-180MB** |
| **Processing** | 100MB | 50MB | **-50MB** |
| **TOTAL Peak** | 450MB+ | **220MB** | **-230MB** |

‚Üí **Gi·∫£m ƒë∆∞·ª£c 230MB!** üéâ

---

## üéØ K·∫øt Qu·∫£ Mong ƒê·ª£i

### Memory Usage:
- **Startup**: ~80MB
- **First API call**: ~220MB (load model + 50 products)
- **Subsequent calls**: ~180-200MB
- **PEAK**: ~250MB (SAFE trong 512MB!)

### Performance:
- **First call**: 3-5 gi√¢y (load model)
- **Next calls**: 1-2 gi√¢y
- **Search trong**: 50 products (thay v√¨ t·∫•t c·∫£)

---

## ‚ö†Ô∏è L∆∞u √ù Quan Tr·ªçng

### Ch·ªâ Search 50 Products

API gi·ªù ch·ªâ search trong **50 products ƒë·∫ßu ti√™n** trong database.

**N·∫øu b·∫°n c√≥ > 50 products:**

**Option 1: TƒÉng MAX_PRODUCTS (n·∫øu c√≥ √≠t products)**
```env
MAX_PRODUCTS=100  # N·∫øu c√≥ kho·∫£ng 100 products
MAX_PRODUCTS=200  # N·∫øu c√≥ 200 products v√† d√πng Starter plan
```

**Option 2: Implement Pagination**
- Chia database th√†nh chunks
- Search t·ª´ng chunk
- Combine results

**Option 3: N√¢ng C·∫•p Render Plan**
- Starter ($7/th√°ng) ‚Üí 2GB RAM
- C√≥ th·ªÉ set `MAX_PRODUCTS=1000` ho·∫∑c kh√¥ng gi·ªõi h·∫°n

### ∆Ø·ªõc T√≠nh Memory theo S·ªë Products:

| Products | Memory | Plan C·∫ßn |
|----------|--------|----------|
| 50 | ~220MB | Free (512MB) ‚úÖ |
| 100 | ~280MB | Free (512MB) ‚úÖ |
| 200 | ~380MB | Free (borderline) ‚ö†Ô∏è |
| 500+ | 500MB+ | Starter (2GB) üí∞ |

---

## üß™ Test Sau Khi Deploy

### 1. Health Check
```bash
curl https://your-app.onrender.com/api/v1/health
```

Ph·∫£i tr·∫£ v·ªÅ:
```json
{
  "status": "healthy",
  "message": "API is running",
  "note": "Model will load on first search request"
}
```

### 2. First Search (S·∫Ω ch·∫≠m!)
```bash
curl -X POST https://your-app.onrender.com/api/v1/search/url \
  -H "Content-Type: application/json" \
  -d '{
    "image_url": "https://picsum.photos/400",
    "top_k": 5
  }'
```

- ‚è±Ô∏è **3-5 gi√¢y** - B√¨nh th∆∞·ªùng (ƒëang load model)
- ‚úÖ Ph·∫£i tr·∫£ v·ªÅ results
- ‚úÖ Kh√¥ng b·ªã crash!

### 3. Second Search (Nhanh h∆°n)
```bash
# G·ªçi l·∫°i request tr√™n
```

- ‚è±Ô∏è **1-2 gi√¢y** - Nhanh h∆°n nhi·ªÅu
- ‚úÖ Model ƒë√£ loaded

### 4. Check Status Chi Ti·∫øt
```bash
curl https://your-app.onrender.com/api/v1/status
```

Ph·∫£i show:
```json
{
  "status": "healthy",
  "model_loaded": true,
  "total_products": 50,
  "cached_features": 0
}
```

---

## üîç Monitor Logs

Sau khi deploy, check logs tr√™n Render:

### ‚úÖ Logs T·ªët (Ph·∫£i th·∫•y):
```
‚úÖ "Services will be initialized on first request"
‚úÖ "Lazy loading search service components..."
‚úÖ "Loaded 50 products (limit: 50)"
‚úÖ "CLIP model loaded successfully"
‚úÖ "Found X similar products using on-demand computation"
```

### ‚ùå Logs X·∫•u (Kh√¥ng ƒë∆∞·ª£c th·∫•y):
```
‚ùå "Ran out of memory"
‚ùå "OOMKilled"
‚ùå "Instance failed"
‚ùå "Memory error"
```

---

## üÜò N·∫øu V·∫™N B·ªã L·ªói

### Solution 1: Gi·∫£m Products H∆°n N·ªØa
```env
MAX_PRODUCTS=25   # Gi·∫£m xu·ªëng 25
```

### Solution 2: Gi·∫£m TOP_K
```env
TOP_K=3   # Ch·ªâ tr·∫£ 3 results
```

### Solution 3: TƒÉng Threshold
```env
SIMILARITY_THRESHOLD=0.8   # Ch·ªâ tr·∫£ results r·∫•t gi·ªëng
```

### Solution 4: Upgrade Plan (KHUY√äN D√ôNG)

**Render Starter - $7/th√°ng:**
- 512MB ‚Üí **2GB RAM** (4x nhi·ªÅu h∆°n!)
- Load ƒë∆∞·ª£c nhi·ªÅu products
- Nhanh h∆°n nhi·ªÅu
- C√≥ th·ªÉ cache features

**V·ªõi Starter plan, config l·∫°i:**
```env
MAX_PRODUCTS=500
CACHE_PRODUCTS=true
LAZY_LOAD_MODEL=false
MAX_BATCH_SIZE=16
```

---

## üìà Scaling Strategy

### Stage 1: Free Tier (Current)
- 50 products
- On-demand computation
- 1-2s per search
- Good for MVP/testing

### Stage 2: Starter Plan ($7/month)
- 500 products
- Can enable caching
- 0.3-0.5s per search
- Good for small production

### Stage 3: Professional ($25/month)
- Unlimited products
- Full caching
- Multiple workers
- Redis caching layer
- < 0.3s per search

---

## üí° Alternative Solutions

N·∫øu kh√¥ng mu·ªën upgrade:

### 1. Pre-compute Features Offline
```python
# Run locally or in background job
# Save features to MongoDB
# API only does similarity comparison
```

### 2. Use External Service
- AWS Lambda
- Google Cloud Functions
- Azure Functions

### 3. Different Architecture
- Separate model service
- Queue-based processing
- Background workers

---

## ‚úÖ Checklist Deploy

- [ ] Added `MAX_PRODUCTS=50` to Render env vars
- [ ] Added `ENABLE_GC=true` to Render env vars
- [ ] Confirmed `CACHE_PRODUCTS=false`
- [ ] Confirmed `LAZY_LOAD_MODEL=true`
- [ ] Updated Start Command with concurrency limit
- [ ] Pushed code to GitHub
- [ ] Deployed on Render
- [ ] Tested health endpoint (must work)
- [ ] Tested search endpoint (first call slow, works!)
- [ ] Tested second search (faster!)
- [ ] Checked logs (no memory errors!)
- [ ] Monitored for 10 minutes (stable!)

---

## üéâ T√≥m T·∫Øt

**Thay ƒë·ªïi ch√≠nh:**
1. ‚úÖ Ch·ªâ load 50 products thay v√¨ t·∫•t c·∫£ ‚Üí **-180MB**
2. ‚úÖ Force garbage collection ‚Üí **-20MB**
3. ‚úÖ Optimize batch processing ‚Üí **-30MB**
4. ‚úÖ **T·ªîNG TI·∫æT KI·ªÜM: ~230MB**

**Memory usage m·ªõi:**
- Peak: ~220-250MB
- Safe trong 512MB free tier! üéØ

**Trade-off:**
- ‚ö†Ô∏è Ch·ªâ search 50 products (c√≥ th·ªÉ tƒÉng n·∫øu c·∫ßn)
- ‚è±Ô∏è V·∫´n ch·∫≠m ~1-2s (ch·∫•p nh·∫≠n ƒë∆∞·ª£c)

**Deploy ngay v√† n√≥ s·∫Ω KH√îNG B·ªä CRASH n·ªØa!** üöÄ
